<!DOCTYPE html>

<html lang="en">
<head>
  <title>Giovanni Luca Marchetti</title>
  <link rel="stylesheet" href="https://latex.vercel.app/style.css">
  <style>
  /* img {
    border: 3px solid #555;
  } */
  figcaption {
  text-align: center;
  }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
</head>


<body class="text-justify">
  <div>
    <h2>
    <p class="author"> Giovanni Luca Marchetti</p>
    </h2>

    <br>

    <div>
      <img class="img-responsive" src="img/glma_better_revised.png" alt="" style="display:block;  margin:auto;" width="50%" height="auto"><br>
    </div>
    <p>I am a postdoctoral researcher at the Department of Mathematics of the Royal Institute of Technology (KTH) in Stockholm, Sweden.</p>

    <p>I apply tools from pure mathematics (algebra, geometry, topology, ...) to <b>machine learning</b> and high-dimensional statistics. More specifically, I am interested in algebro-geometric aspects of deep neural networks, manifold/representation learning, geometric density estimation, and topological data analysis. Check <a href="files/Slides_research.pdf">these slides</a> for a high-level presentation of my research so far.  </p>

    <br>

    <div>
    <figure></figure>
    <img class="img-responsive" src="img/grr.png" alt="" style="display:block;  margin:auto;" width="80%" height="auto"><br>
    <figcaption><a href=https://en.wikipedia.org/wiki/Grothendieck%E2%80%93Riemann%E2%80%93Roch_theorem>Geometry</a> &#8855; Deep Learning</figcaption>
    </figure>
    </div>

    <br>

    <center>
    <p>Resources: <a href="files/CV_academic.pdf">CV</a>,  &nbsp<a href="https://scholar.google.com/citations?user=ePYa2qAAAAAJ&hl=en">Google Scholar</a>,  &nbsp<a href="https://github.com/giovanni-marchetti/">GitHub</a>,  &nbsp<a href="https://x.com/giovannimarchet">X/Twitter</a>,  &nbsp<a href="https://www.linkedin.com/in/giovanni-luca-marchetti-11314126b/">LinkedIn</a> </p> 
    </center>


    <!-- <center>
    <p><a href="files/CV_academic.pdf">CV</a> <br> <a href="https://scholar.google.com/citations?user=ePYa2qAAAAAJ&hl=en">Google Scholar</a><br><a href="https://github.com/giovanni-marchetti/">GitHub</a><br><a href="https://x.com/giovannimarchet">X/Twitter</a><br><a href="https://www.linkedin.com/in/giovanni-luca-marchetti-11314126b/">LinkedIn</a> </p> 
    </center> -->
    <br> 
    <br>
    <br>
  </div>

  <div>
    <h2>
    Publications
    </h2>
    <p>Below you can find a selection of my academic works, subdivided into topics. For a complete list, please visit my Google Scholar profile. The symbol * denotes equal contribution.</p>
    <p><b>Algebraic Geometry of Deep Learning</b>: these works explore the (algebraic) geometry of function spaces defined by neural networks.</p>
    <ul>
      <li><a href="https://arxiv.org/abs/2506.06489">Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks</a> <br>Kunin, Marchetti, Chen, Karkada, Simon, DeWeese, Ganguli, Miolane<br> NeurIPS, 2025 </li>
      <li><a href="https://arxiv.org/abs/2501.18915">An Invitation to Neuroalgebraic Geometry</a> <br> Marchetti*, Shahverdi*,  Mereta*,  Trager*, Kohn*  <br> ICML Spotlight, 2025 </li>
      <li><a href="https://arxiv.org/abs/2505.11846">Learning on a Razor's Edge: the Singularity Bias of Polynomial Neural Networks</a> <br> Shahverdi*, Marchetti*, Kohn* <br> Preprint, 2025 </li>
      <li><a href="https://arxiv.org/abs/2408.17221">Geometry of Lightning Self-Attention: Identifiability and Dimension</a> <br> Henry*, Marchetti*, Kohn* <br> ICLR, 2025 </li>
      <li><a href="https://arxiv.org/abs/2410.00722">On the Geometry and Optimization of Polynomial Convolutional Networks</a> <br> Shahverdi*, Marchetti*, Kohn*<br> AISTATS, 2025 </li>
    </ul>
    <p><b>Equivariant/Invariant Deep Learning</b>: these works explore the interaction between symmetry and deep learning, ranging from the invariant theory of neural networks to equivariant representation learning, with applications to robotics.</p>
    <ul>
      <li><a href="https://arxiv.org/abs/2311.08170">Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach</a> <br> Marchetti, Cesa, Kumar, Behboodi<br> TMLR, 2025 </li>
      <li><a href="https://arxiv.org/abs/2312.08550">Harmonics of Learning: Universal Fourier Features Emerge in Invariant Networks</a> <br> Marchetti, Hillar, Kragic, Sanborn <br> COLT, 2024 </li>
      <li><a href="https://arxiv.org/abs/2207.03116">Equivariant Representation Learning via Class-Pose Decomposition</a> <br> Marchetti*, Tegner*, Varava, Kragic<br> AISTATS, 2023 </li>
      <li><a href="https://arxiv.org/abs/2301.05231">Equivariant Representation Learning in the Presence of Stabilizers</a> <br> Rey*, Marchetti*, Kragic, Jarnikov, Holenderski<br> ECML-PKDD, 2023 </li>
      <li><a href="https://arxiv.org/abs/2309.05346">Learning Geometric Representations of Objects via Interaction</a> <br> Reichlin*, Marchetti*, Yin, Varava, Kragic<br> ECML-PKDD, 2023 </li>
      <li><a href="https://arxiv.org/abs/2207.08673">Back to the Manifold: Recovering from Out-of-Distribution States</a> <br> Reichlin, Marchetti, Yin, Ghadirzadeh, Kragic<br> IROS, 2022 </li>    
    <!-- <li><a href="https://arxiv.org/abs/2409.10967">Relative representations: Topological and Geometric Perspectives</a> <br> Garcia-Castellanos, Marchetti, Kragic, Scolamiero<br> NeurIPS Workshop (UniReps), 2024 </li>                -->
    </ul>
    <p><b>Computational Geometry</b>: these works concern high-dimensional Voronoi tessellations and Delaunay triangulations, with applications to density estimation and active learning.</p>
    <ul>
      <li><a href="https://arxiv.org/abs/2409.05671">HyperSteiner: Computing Heuristic Hyperbolic Steiner Minimal Trees</a> <br>Garcia-Castellanos*, Medbouhi*, Marchetti, Bekkers, Kragic <br> ALENEX, 2025 </li>    
      <li><a href="https://arxiv.org/abs/2404.08608">Hyperbolic Delaunay Geometric Alignment</a> <br>Medbouhi, Marchetti, Polianskii, Kravberg, Poklukar, Varava, Kragic<br> ECML-PKDD, 2024 </li>
      <li><a href="https://arxiv.org/abs/2210.03964">An Efficient and Continuous Voronoi Density Estimator</a> <br> Marchetti, Polianskii, Varava, Pokorny, Kragic<br> AISTATS Oral, 2023 </li>
      <li><a href="https://arxiv.org/abs/2206.08061">Active Nearest Neighbor Regression Through Delaunay Refinement</a> <br> Kravberg*, Marchetti*, Polianskii*, Varava, Pokorny, Kragic<br> ICML, 2022 </li>
      <li><a href="https://arxiv.org/abs/2206.08051">Voronoi Density Estimator: Computation, Compactification and Convergence</a> <br>Polianskii*, Marchetti*, Kravberg, Varava, Pokorny, Kragic<br> UAI, 2022 </li>
    </ul>    
    <p><b>Other</b>: these works concern various topics in pure mathematics, e.g., category theory and combinatorics.</p>
      <ul>
        <li><a href="https://arxiv.org/abs/2502.13518">Rubik's Abstract Polytopes</a> <br>Marchetti<br> Preprint, 2025 </li>
        <li><a href="https://arxiv.org/abs/1501.04658">Hearts and Towers in Stable <span>&#8734;</span>-Categories</a> <br>Fiorenza, Loregian, Marchetti<br> Journal of Homotopy and Related Structures, 2019 </li>
      </ul>
  
    <p><b>Thesis</b>: I obtained my doctoral degree from KTH in 2024 under the supervision of Prof. Danica Kragic. Below you can download the thesis.</p>
    <ul>
      <li><a href="files/PhD_Thesis.pdf">On Symmetries and Metrics in Geometric Inference</a> <br> KTH, 2024 </li>
    </ul>
    
    </div>
  

</body>


</html>
